\documentclass[a4paper,12pt]{article}
\usepackage{researchpack}

\usepackage{xcolor}
\newcommand{\stefano}[1]{{\bf \textcolor{violet}{{[Stefano: #1]}}}}
\newcommand{\lime}{\textsc{lime}}
\newcommand{\mojito}{\textsc{mojito}}

\title{\mojito: Coactive Learning with \lime}
\author{--}

\begin{document}
\maketitle

\paragraph{Setting.} Given:

\begin{itemize}

    \item a dataset $\calD = \{ x_1, \ldots, x_n \} \subseteq \calX$

    \item a set of labels $\calY$

    \item a target function $f^* : \calX \to \calY$ \stefano{or a joint distrib.}

    \item an \textbf{interpretable (joint) feature map} $\vpsi(x,y)$

        e.g. in document classification it could map documents to their
        1-grams; in image classification it could map images to
        super-pixels; in food recommendation it could map products to
        simple flavors

    \item a class of \textbf{uninterpretable} models $\calF = \{ f : \calX \to \calY \}$

    \item a class of \textbf{interpretable} models $\calG = \{ g : \calX \to \calY \}$

        As in \lime~\cite{ribeiro2016should}, we target linear
        classifiers only:
        %
        $$ g(x) = \argmax_{y\in\calY} \; \inner{w}{\vpsi(x,y)} $$
        %
        Here $\vpsi$ are \textbf{interpretable} features.

    \item an \textbf{active learner} providing three methods:

        \begin{itemize}
            \item $x \gets \textsc{SelectQuery}(f,\calD)$
            \item $y \gets \textsc{Infer}(f,x)$
            \item $f' \gets \textsc{Update}(f,x,y,\bar{y})$
        \end{itemize}

    \item an \textbf{interpretable model generator} (e.g.~\lime)
        providing a method:

        \begin{itemize}
            \item $g \gets \textsc{Explain}(f,x,[y])$
        \end{itemize}

\end{itemize}

\textbf{Goal}: learn an estimate $f$ of $f^*$ by interacting with the user via
coactive learning, providing candidate predictions and their explanation at
each iteration. The user is free to improve the candidate prediction (and
potentially the accompanying explanation).

\paragraph{Algorithm template.} See Algorithm~\ref{alg:mojito}.

\begin{algorithm*}[t]
    \caption{\label{alg:mojito} The \mojito\ algorithm.}
    \begin{algorithmic}[1]
        \Procedure{\mojito}{$\calD$, $\vpsi$, $T$}
            \State $f^1 \gets \text{initial model}$
            \For{ $t = 1, \dots, T$ }
                \State $x^t \gets \textsc{SelectQuery}(f^t, \calD)$
                \State $y^t \gets \textsc{Infer}(f^t, x^t)$
                \State $g^t \gets \textsc{Explain}(f^t, x^t,[y^t])$
                \State Obtain improved prediction $\bar{y}^t$ from $x^t$, $y^t$, $g^t$
                \State [Obtain improved explanation $\bar{g}^t$ from $x^t$, $y^t$, $g^t$]
                \State $f^{t+1} \gets \textsc{Update}(f^t,x^t,y^t,\bar{y}^t,[g^t,\bar{g}^t])$
            \EndFor
            \State $\textbf{return} f^{T+1}$
        \EndProcedure
    \end{algorithmic}
\end{algorithm*}

\paragraph{Coactive Learning.} Coactive learning~\cite{shivaswamy2015coactive}
is an interactive learning framework whereby, at each iteration, the learner
presents a prediction $y^t$ of some example $x^t$ to the user, and the user
produces an improved prediction $\bar{y}^t$ (if possible). Learning relies on
the fact that $\bar{y}^t$ is a better prediction than $y^t$, which induces a
``ranking constraint'' among predictions.

The main difference with respect to active learning (see
\cite{settles2010active} for an in-depth survey) is that the learner presents
the user both an example $x^t$ and a prediction $y^t$; on the contrary, in
active learning only $x^t$ is presented. In other words, active learning does
not aim at ``explaining'' the current prediction of the classifier to the
annotator.

\stefano{Contrary to structured-output prediction, in binary and multi-class
classification there is no ranking between labels. The only way to ``improve''
a prediction $y^t$ is to change it to the correct label, i.e., $\bar{y}^t =
f^*(x^t)$. In this case $\alpha$-informativeness does not make sense anymore.
However, the user/oracle may provide the actual correct label with a certain
probability rather than with certainty.}

The candidate prediction $y^t$ is useful because the explanation is based on
it.

\bibliographystyle{unsrt}
\bibliography{notes}
\end{document}
